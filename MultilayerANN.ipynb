{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        #Status of each step, Add Layers must be fixed before Passing in Data\n",
    "        self.status = False\n",
    "        #A list of Hidden neurons, ith index is # of Neurons of ith layer\n",
    "        self.hiddenNeurons = []\n",
    "        #A list of Hidden Weights and Biases, ith index is Weight matrix to the next layer\n",
    "        self.weights = []\n",
    "        self.biases  = []\n",
    "        #A list of dZ[i]\n",
    "        self.dZ = []\n",
    "        #A list of A[i], where A[0] is X(the inputs), A[n] is the outputs\n",
    "        self.Z = []\n",
    "        self.A = [] \n",
    "        #A list of Activation Functions\n",
    "        self.activation_functions = []\n",
    "        #Other\n",
    "        self.n_in  = None #Number of Inputs\n",
    "        self.n_out = None #Number of desired Outputs\n",
    "        self.alpha = 0.1 #Adjustable\n",
    "        self.epoch = 500 #Adjustable\n",
    "\n",
    "    def ReLU(self, Z):\n",
    "        return np.maximum(0, Z)\n",
    "    \n",
    "    def ReLU_deriv(self, Z):\n",
    "        return Z > 0\n",
    "    \n",
    "    def SoftMax(self, Z):\n",
    "        A = np.exp(Z) / sum(np.exp(Z))\n",
    "        return A\n",
    "    \n",
    "    def one_hot(self, Y):\n",
    "        one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "        one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "        return one_hot_Y.T\n",
    "    \n",
    "    def get_predictions(self, A):\n",
    "        return np.argmax(A, 0)\n",
    "    \n",
    "    def get_accuracy(self, predictions, actual):\n",
    "        passed = np.sum(predictions == actual)\n",
    "        accuracy = passed / actual.size\n",
    "        return passed, accuracy\n",
    "    \n",
    "    def forward_propagation(self, i=0):\n",
    "        if i == len(self.weights):\n",
    "            return\n",
    "        self.Z[i] = self.weights[i] @ self.A[i]\n",
    "        self.A[i+1] = self.ReLU(self.Z[i] + self.biases[i])\n",
    "        self.forward_propagation(i+1)\n",
    "\n",
    "    # def backward_propagation(self):\n",
    "\n",
    "    #Generate Neural network Structure\n",
    "    def addLayer(self, neurons, activation_function):\n",
    "        if self.status: return\n",
    "        allowed = ['relu']\n",
    "        self.hiddenNeurons.append(neurons)\n",
    "        if activation_function.lower() in allowed:\n",
    "            self.activation_functions.append(activation_function)\n",
    "        else:\n",
    "            print('error_activation function not found')\n",
    "    \n",
    "    def init_params(self):\n",
    "        self.weights.append(np.random.rand(self.hiddenNeurons[0] , self.n_in) - 0.5)\n",
    "        self.biases.append(np.random.rand(self.hiddenNeurons[0], 1) - 0.5)\n",
    "        for n in range(len(self.hiddenNeurons)-1):\n",
    "            self.weights.append(np.random.rand(self.hiddenNeurons[n+1],self.hiddenNeurons[n]) - 0.5)\n",
    "            self.biases.append(np.random.rand(self.hiddenNeurons[n+1], 1) - 0.5)\n",
    "            self.Z.append(None)\n",
    "            self.A.append(None)\n",
    "        self.Z.append(None)#offset\n",
    "        self.A.append(None)#offset\n",
    "        self.status = True\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        #Must be at least one Hidden layer\n",
    "        self.A.append(x_train)\n",
    "        m, _ = x_train.shape\n",
    "        self.n_in  = m\n",
    "        self.n_out = self.hiddenNeurons[-1]\n",
    "        self.init_params()\n",
    "        self.one_hot_Y = self.one_hot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/tanhoangminhco/Documents/Coding/Python/Machine Learning/datasets/mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "\n",
    "train_set = data[1000:].T\n",
    "y_train = train_set[0]\n",
    "x_train = train_set[1:] / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork()\n",
    "nn.addLayer(neurons=3, activation_function='relu')\n",
    "nn.addLayer(neurons=5, activation_function='relu')\n",
    "nn.addLayer(neurons=10, activation_function='relu')\n",
    "nn.fit(x_train, y_train)\n",
    "nn.forward_propagation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.biases[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
